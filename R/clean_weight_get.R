# WARNING - Generated by {fusen} from dev/flat_teaching.Rmd: do not edit by hand

#' Comprehensive Pig Weight Data Processing Pipeline
#'
#' @description
#' Advanced weight data cleaning and validation system for porcine growth analysis, 
#' integrating multiple quality control checks and statistical validation steps.
#'
#' @param data Input `data.table` containing processed pig weight records
#'   - **Must contain columns**: 
#'     \itemize{
#'       \item `responder` (unique identifier)
#'       \item `location` (measurement location)
#'       \item `date` (date of measurement)
#'       \item `seq_days` (sequence days)
#'       \item `seq_in_location` (sequence in location)
#'       \item `seq_in_day` (sequence in day)
#'       \item `weight` (weight measurements in grams)
#'     }
#'   - **Requires output** from `preprocess_data()`
#'   - Supports parallel processing via data.table optimizations
#'
#' @param my_break Target weight range specification
#'   - **Format**: Numeric vector of length 2 `[lower, upper]`
#'   - **Units**: Kilograms (kg)
#'   - **Constraint**: `my_break[1] < my_break[2]`
#'   - **Example**: `c(30, 120)` for 30-120kg range
#'
#' @param range_offset Weight range extension buffer
#'   - **Purpose**: Extends target range for boundary cases
#'   - **Units**: Kilograms (kg)
#'   - **Default**: `0.5`
#'   - **Constraint**: Must be positive value
#'
#' @param min_days Minimum observation period requirement
#'   - **Purpose**: Filters short-term measurements
#'   - **Units**: Days
#'   - **Default**: `35`
#'
#' @param min_records Minimum data points per responder
#'   - **Purpose**: Ensures sufficient data density
#'   - **Default**: `20`
#'
#' @param min_na_perc Maximum allowable missing data ratio
#'   - **Purpose**: Controls data completeness
#'   - **Format**: Proportion between 0-1
#'   - **Default**: `0.3` (30% maximum NA)
#'
#' @param w_threshold Robust regression outlier cutoff
#'   - **Purpose**: Identifies statistical outliers
#'   - **Default**: `0.5`
#'   - **Technical**: Weight threshold for MASS::rlm weights
#'   - **Constraint**: Typically 0.5-1.0
#'
#' @param maxit Maximum iterations for robust regression
#'   - **Purpose**: Controls model convergence
#'   - **Default**: `1000`
#'
#' @param entry_weight_limit Maximum allowable entry weight
#'   - **Purpose**: Filters over-conditioned starters
#'   - **Units**: Kilograms (kg)
#'   - **Default**: `65`
#'   - **Constraint**: Must be < exit_weight_limit
#'
#' @param exit_weight_limit Minimum required exit weight
#'   - **Purpose**: Ensures market readiness
#'   - **Units**: Kilograms (kg)
#'   - **Default**: `85`
#'   - **Constraint**: Must be > entry_weight_limit
#'
#' @param max_weight_limit Physiological weight ceiling
#'   - **Purpose**: Removes biologically implausible values
#'   - **Units**: Kilograms (kg)
#'   - **Default**: `150`
#'   - **Constraint**: Should exceed exit_weight_limit
#'
#' @param days_extend Prediction window extension
#'   - **Purpose**: Forecast period for growth modeling
#'   - **Units**: Days
#'   - **Default**: `30`
#'   - **Constraint**: Must be ≥ 0
#'
#' @param step Prediction interval granularity
#'   - **Purpose**: Controls forecast resolution
#'   - **Units**: Days
#'   - **Default**: `1`
#'
#' @param degree Polynomial regression complexity
#'   - **Purpose**: Determines growth curve flexibility
#'   - **Default**: `2` (quadratic)
#'   - **Constraint**: 1 ≤ degree ≤ 3
#'
#' @param print_details Diagnostic output control
#'   - **Purpose**: Enables detailed process reporting
#'   - **Default**: `FALSE`
#'   - **Note**: Overridden by `quiet = TRUE`
#'
#' @param quiet Comprehensive silencing control
#'   - **Purpose**: Suppresses all non-essential output
#'   - **Default**: `FALSE`
#'   - **Effect**:
#'     \itemize{
#'       \item Disables progress messages
#'       \item Suppresses warnings
#'       \item Overrides print_details
#'     }
#'
#' @details
#' **Multi-Stage Processing Pipeline**:
#' \enumerate{
#'   \item **Input Validation**
#'     \itemize{
#'       \item Data structure verification
#'       \item Parameter sanity checks
#'       \item Column existence validation
#'     }
#'     
#'   \item **Data Cleansing**
#'     \itemize{
#'       \item Unit conversion (kg ↔ g)
#'       \item Invalid responder filtering
#'       \item Temporal consistency checks
#'       \item Missing data thresholding
#'     }
#'     
#'   \item **Statistical Validation**
#'     \itemize{
#'       \item Robust regression modeling (MASS::rlm)
#'       \item Outlier detection and removal
#'       \item Growth curve analysis
#'     }
#'     
#'   \item **Biological Plausibility Checks**
#'     \itemize{
#'       \item Entry/exit weight validation
#'       \item Physiological limit enforcement
#'       \item Growth trajectory analysis
#'     }
#' }
#'
#' **Quality Control Metrics**:
#' \itemize{
#'   \item Responder-level completeness analysis
#'   \item Temporal coverage assessment
#'   \item Measurement consistency scoring
#'   \item Outlier impact quantification
#' }
#'
#' @return Structured `list` containing:
#' \itemize{
#'   \item `cleaned_data`: 
#'     \itemize{
#'       \item Validated `data.table` with outlier flags
#'       \item Contains columns: 
#'         \itemize{
#'           \item `responder`, `location`, `date`
#'           \item `seq_days`, `seq_in_location`, `seq_in_day`
#'           \item `weight`, `rlm_predict`, `rlm_outliers`
#'         }
#'     }
#'   \item `deleted_responders`: 
#'     \itemize{
#'       \item Character vector of removed IDs
#'       \item Categorized removal reasons
#'     }
#'   \item `validation_metrics`:
#'     \itemize{
#'       \item Pre/post-cleaning responder counts
#'       \item Outlier percentage analysis
#'       \item Weight limit compliance stats
#'     }
#' }
#'
#' @seealso
#' \itemize{
#'   \item [`preprocess_data()`] For input data preparation
#' }
#'
#' @importFrom data.table := .N .SD
#' @importFrom MASS rlm
#' @importFrom purrr map map2
#' @importFrom stats predict
#' @export
#' @examples
#' result_nedap <- preprocess_data(data = mintyr::nedap, station_type = "nedap")
#' clean_weight <- clean_weight_get(result_nedap, my_break = c(30,120), range_offset = 0.5)
#' head(clean_weight)

clean_weight_get <- function(data,
                             my_break,
                             range_offset = 0.5,
                             min_days = 35,
                             min_records = 20,
                             min_na_perc = 0.3,
                             w_threshold = 0.5,
                             maxit = 1000,
                             entry_weight_limit = 65,
                             exit_weight_limit = 85,
                             max_weight_limit = 15,
                             days_extend = 30,
                             step = 1,
                             degree = 2,
                             print_details = FALSE,
                             quiet = FALSE) {

  # Build configuration list
  config <- list(
    min_days = min_days,
    min_records = min_records,
    min_na_perc = min_na_perc,
    w_threshold = w_threshold,
    maxit = maxit,
    entry_weight_limit = entry_weight_limit,
    exit_weight_limit = exit_weight_limit,
    max_weight_limit = max_weight_limit,
    days_extend = days_extend,
    step = step,
    degree = degree
  )

  # Define process function based on quiet parameter
  process_fn <- if (quiet) {
    function(expr) suppressMessages(suppressWarnings(expr))
  } else {
    function(expr) expr
  }

  # Main processing logic wrapped in process_fn
  process_fn({
    tryCatch({
      validate_params(data, my_break, range_offset, config)

      # Clean and process weight data
      cleaned_data <- data |>
        clean_and_filter_weight_data(
          min_days = config$min_days,
          min_records = config$min_records,
          min_na_perc = config$min_na_perc,
          max_weight_limit = config$max_weight_limit,
          print_details = print_details && !quiet
        ) |>
        remove_outliers_using_rlm(
          maxit = config$maxit,
          w_threshold = config$w_threshold
        ) |>
        validate_responder_weights(
          entry_weight_limit = config$entry_weight_limit,
          exit_weight_limit = config$exit_weight_limit
        )

      return(cleaned_data)

    }, error = function(e) {
      if (!quiet) {
        cli::cli_alert_danger("Error in clean_weight_get: {e$message}")
      }
      return(NULL)
    }, warning = function(w) {
      if (!quiet) {
        cli::cli_alert_warning("Warning in clean_weight_get: {w$message}")
      }
    })
  })
}

validate_params <- function(data, my_break, range_offset, config) {
  # Check data.table
  if (!data.table::is.data.table(data)) {
    cli::cli_abort("Input 'data' must be a data.table")
  }

  # Check required columns
  required_cols <- c("responder", "location", "date", "seq_days",
                     "seq_in_location", "seq_in_day", "weight")
  missing_cols <- setdiff(required_cols, names(data))
  if (length(missing_cols) > 0) {
    cli::cli_abort(c(
      "Missing required columns:",
      "x" = "{.val {missing_cols}}",
      "i" = "Input must be output from process_adg_data()"
    ))
  }

  # Validate my_break
  if (!is.numeric(my_break) || length(my_break) != 2 || any(is.na(my_break))) {
    cli::cli_abort("my_break must be a numeric vector of length 2 without NA values")
  }
  if (my_break[1] >= my_break[2]) {
    cli::cli_abort("my_break[1] must be less than my_break[2]")
  }

  # Validate range_offset
  if (!is.numeric(range_offset) || length(range_offset) != 1 || is.na(range_offset)) {
    cli::cli_abort("range_offset must be a single numeric value")
  }
  if (range_offset <= 0) {
    cli::cli_abort("range_offset must be positive")
  }

  # Validate configuration parameters
  required_config <- c("min_days", "min_records", "min_na_perc",
                       "w_threshold", "maxit", "entry_weight_limit",
                       "exit_weight_limit", "max_weight_limit",
                       "days_extend", "step", "degree")

  missing_config <- setdiff(required_config, names(config))
  if (length(missing_config) > 0) {
    cli::cli_abort(c(
      "Missing required config parameters:",
      "x" = "{.val {missing_config}}"
    ))
  }

  # Validate numeric configuration parameters
  for (param in required_config) {
    if (!is.numeric(config[[param]]) || length(config[[param]]) != 1 || is.na(config[[param]])) {
      cli::cli_abort("Config parameter '{param}' must be a single numeric value")
    }
  }

  # Validate specific parameter ranges
  if (config$min_days <= 0) cli::cli_abort("min_days must be positive")
  if (config$min_records <= 0) cli::cli_abort("min_records must be positive")
  if (config$min_na_perc < 0 || config$min_na_perc > 1) {
    cli::cli_abort("min_na_perc must be between 0 and 1")
  }
  # if (config$max_weight_limit <= config$exit_weight_limit) {
  #   cli::cli_abort("max_weight_limit must be greater than exit_weight_limit")
  # }
}

clean_and_filter_weight_data <- function(data, min_days, min_records, min_na_perc, print_details, max_weight_limit) {
  responder <- . <- weight <- max_weight <- location <- date_length <- n <- 
  date_na <- row_sum <- test_days_less_than_40 <- test_records_less_than_20 <-
  data_na_greater_than_one_third <- seq_in_location <- seq_days <- seq_in_day    <- NULL
  # Convert kg to g
  max_weight_g <- max_weight_limit * 1000

  # Set key for faster operations on responder
  data.table::setkey(data, responder)

  cli::cli_h1("Pre-cleaning Low Quality Records")

  # Calculate the maximum weight for each responder
  cli::cli_process_start("Calculating maximum weight boundary")

  max_weights <- data[, .(max_weight = max(weight, na.rm = TRUE)), by = responder]

  cli::cli_process_done()

  # Find responders whose all weights are less than max_weight_g
  responder_to_delete <- max_weights[max_weight < max_weight_g, responder]

  # Print the number of responders to be deleted due to low weight
  if(length(responder_to_delete) > 0){
    cli::cli_alert_danger("Removing records with max weight less than {.field {max_weight_limit}kg} will delete {length(responder_to_delete)} responders")
  } else {
    cli::cli_alert_info("Removing records with max weight less than {.field {max_weight_limit}kg} will not delete responder")
  }

  # Filter and process data
  cli::cli_process_start("Processing data quality checks")
  temp <- data[!responder %in% responder_to_delete,
               `:=`(
                 n = .N,  # Count of records for each responder and location
                 date_na = sum(is.na(weight)),  # Count of NA weights
                 date_length = as.integer(difftime(max(date), min(date), units = "days"))  # Date range in days
               ),
               by = .(responder, location)
  ][, `:=`(
    test_days_less_than_40 = date_length < min_days,  # Test if date range is less than {min_days} days
    test_records_less_than_20 = n < min_records,  # Test if number of records is less than {min_records}
    data_na_greater_than_one_third = ifelse(date_length == 0, FALSE, date_na/date_length >= min_na_perc)  # Test if more than {min_na_perc*100}% of data is NA
  )]

  # Calculate row_sum and find outliers
  temp[, row_sum := test_days_less_than_40 + test_records_less_than_20 + data_na_greater_than_one_third]
  outlier <- unique(temp[row_sum > 0 & !is.na(responder), .(responder, location, date_na, test_days_less_than_40, test_records_less_than_20, data_na_greater_than_one_third, row_sum)])
  cli::cli_process_done()

  # Final result: keep rows with row_sum == 0 and weight >= max_weight_g
  step1_res <- temp[row_sum == 0 & weight >= max_weight_g, .(responder, location, date, seq_in_location, seq_days, seq_in_day, weight)]

  # Print information about outliers
  if(nrow(outlier) > 0){
    cli::cli_alert_danger("Removing low quality records will delete {.field {nrow(outlier)}} responders")
    cli::cli_alert_success("Pre-cleaning low quality records completed!")

    # Calculate counts for each reason
    n_short_period <- length(unique(outlier[test_days_less_than_40 == TRUE, responder]))
    n_few_records <- length(unique(outlier[test_records_less_than_20 == TRUE, responder]))
    n_missing_data <- length(unique(outlier[data_na_greater_than_one_third == TRUE, responder]))

    # Print summary of reasons
    #cli::cli_rule("Quality Check Summary")
    cli::cli_bullets(c(
      "*" = "Test period less than {.field {min_days}} days: {.field {cli::col_red(n_short_period)}} responders",
      "*" = "Less than {.field {min_records}} records: {.field {cli::col_red(n_few_records)}} responders",
      #"*" = sprintf("More than %.0f%% of data is missing: %d responders", min_na_perc*100, n_missing_data)
      "*" = "More than {.field {min_na_perc * 100}%} of data is missing: {.field {cli::col_red(n_missing_data)}} responders"
    ))

    # Print detailed outlier information if print_details is TRUE
    if(print_details) {
      cli::cli_rule("Low Quality Details")

      # Sort outlier by responder
      outlier <- outlier[order(responder)]

      for(resp in unique(outlier$responder)) {
        subset_records <- outlier[responder == resp]
        locations_str <- paste(subset_records$location, collapse = "/")

        # Collect reasons for each record
        reasons <- character(0)
        if(any(subset_records$test_days_less_than_40))
          reasons <- c(reasons, sprintf("<%d days", min_days))
        if(any(subset_records$test_records_less_than_20))
          reasons <- c(reasons, sprintf("<%d records", min_records))
        if(any(subset_records$data_na_greater_than_one_third))
          reasons <- c(reasons, sprintf(">%.0f%% NA", min_na_perc*100))

        reasons_str <- paste(reasons, collapse = ", ")

        cli::cli_alert_danger("Responder {.val {resp}}: {locations_str} ({reasons_str})")
      }
    }
  } else {
    cli::cli_alert_success("No responder is deleted due to data quality")
  }

  # Combine all deleted responders and print summary
  deleted_responders <- unique(c(responder_to_delete, outlier$responder))
  deleted_responders <- deleted_responders[!is.na(deleted_responders)]  # Remove NA values

  if(length(deleted_responders) > 0) {
    cli::cli_rule("Deleted Responders")
    cli::cli_alert_warning("Total deleted responder{?s}: {.field {cli::col_red(length(deleted_responders))}}")
    cli::cli_code(sprintf('c("%s")', paste(deleted_responders, collapse = '", "')))
  }

  return(step1_res)
}
process_rlm_results <- function(data, w_threshold, ...) {
  responder <- safe_rlm <- rlm_predict <- model_rlm <- w <- outliers <- NULL
  n_responders <- nrow(data)
  if (n_responders == 0) {
    cli::cli_alert_warning("No data to process")
    return(NULL)
  }

  # Print basic summary
  cli::cli_alert_info("Total responders processed: {.field {n_responders}}")

  tryCatch({
    cli::cli_process_start("Detecting weight outliers")
    cli::cli_progress_step("Fitting robust regression models", spinner = TRUE)
    # Quietly apply lmrob function
    saferlm <- purrr::quietly(.f = MASS::rlm)

    # Process data using data.table syntax for efficiency
    temp1 <- data[, `:=`(safe_rlm = purrr::map2(data, responder, \(df, resp_id, ...) {
      result <- saferlm(..., data = df)
      # 打印警告信息（如果有）
      if (length(result$warnings) > 0) {
        cli::cli_alert_warning("Warnings for responder {resp_id}: {paste(result$warnings, collapse = '; ')}")
      }
      result
    }, ...))
    ][, `:=`(
      model_rlm = purrr::map(safe_rlm, \(x) x$result)
    )]
    cli::cli_progress_update()

    # Generate predictions and calculate weights
    temp2 <- temp1[, rlm_predict := purrr::map(model_rlm, stats::predict)
    ][, w := purrr::map(model_rlm, \(x) x$w)
    ][, `:=`(outliers = purrr::map(w, \(x) x < w_threshold))]

    # Clean up and expand data
    temp3 <- temp2[, c("safe_rlm", "model_rlm") := NULL][, {
      dt <- data.table::as.data.table(data[[1]])
      dt[, `:=`(
        rlm_predict = unlist(rlm_predict),
        rlm_outliers = unlist(outliers))]
      dt}, by = responder]

    cli::cli_process_done()

    # Add some basic statistics
    n_outliers <- sum(temp3$rlm_outliers, na.rm = TRUE)
    outlier_percent <- round(n_outliers/nrow(temp3) * 100, 2)

    #cli::cli_alert_success("Analysis completed:")
    cli::cli_bullets(c(
      "*" = "Outliers detected: {.field {cli::col_red(n_outliers)}}",
      "*" = "Outlier percentage: {.field {cli::col_red(outlier_percent)}}{cli::col_red('%')}"
    ))

    return(temp3)

  }, error = function(e) {
    cli::cli_alert_danger("Error during processing: {e$message}")
    return(NULL)
  }, warning = function(w) {
    cli::cli_alert_warning("Warning during processing: {w$message}")
    invisible()
  })
}
remove_outliers_using_rlm <- function(data, w_threshold, maxit) {
  . <- responder <- rlm_outliers <- NULL
  # Count initial responders
  begin_responder <- unique(data[, .(responder)])

  # Generate nested data format
  data <- data[, .(data = list(.SD)), by = responder]

  cli::cli_h1("Abnormal Weight Detection")

  # Process data using RANSAC
  tryCatch({
    lm_results <- process_rlm_results(data = data, w_threshold = w_threshold, maxit = maxit,
                                      weight ~ seq_days + I(seq_days^2))

    # Count remaining responders after outlier removal
    end_responder <- unique(lm_results[rlm_outliers == FALSE, .(responder)])
    responder_to_delete <- begin_responder[!end_responder, on = "responder"]
    deleted_responders <- responder_to_delete$responder

    # Print information about deleted responders
    if (nrow(responder_to_delete) > 0) {
      cli::cli_alert_warning(
        "Detecting outliers using model will delete {.field {cli::col_red(nrow(responder_to_delete))}} responders"
      )

      cli::cli_h3("Deleted responders")
      cli::cli_code(sprintf(
        'c("%s")',
        paste(deleted_responders, collapse = '", "')))
    } else {
      cli::cli_alert_success("No responders will be deleted based on outlier detection")
    }

    # Remove outliers and affected responders
    lm_results[!responder %in% responder_to_delete$responder]
  }, error = function(e) {
    cli::cli_process_failed()
    cli::cli_alert_danger("Error: {conditionMessage(e)}")
    stop()
  })
}
get_extreme_weights <- function(data, seq_days, direction, weight_type) {
  . <- responder <- temp <- location <- rlm_predict <- NULL
  data[, keyby = .(responder), `:=`(temp, data.table::frankv(direction * seq_days, ties.method = "dense") <= 2)]
  filtered_data <- data[temp == TRUE, keyby = .(responder, location), .(temp_weight = stats::median(rlm_predict))]
  data.table::setnames(filtered_data, "temp_weight", weight_type)
  return(filtered_data)
}
validate_responder_weights <- function(data, entry_weight_limit, exit_weight_limit) {
  rlm_outliers <- seq_days <- min_weight <- . <- responder <- max_weight <- NULL

  # Filter out outliers
  filtered_data <- data[rlm_outliers == FALSE]

  cli::cli_h1("Validating Responder Weights")

  # Get minimum weight
  min_weights <- get_extreme_weights(filtered_data, seq_days, 1, "min_weight")

  # Check entry weight
  overweight_responders <- unique(min_weights[min_weight > (entry_weight_limit * 1000), .(responder)])
  num_overweight <- nrow(overweight_responders)

  # Get maximum weight
  data_filtered <- data[!responder %in% overweight_responders$responder]
  max_weights <- get_extreme_weights(data_filtered, seq_days, -1, "max_weight")

  # Check exit weight
  underweight_responders <- unique(max_weights[max_weight < (exit_weight_limit * 1000), .(responder)])
  num_underweight <- nrow(underweight_responders)

  # Entry weight check results
  if (num_overweight > 0) {
    cli::cli_alert_danger(
      "Found {.field {cli::col_red(num_overweight)}} responder{?s} exceeding entry weight limit of {.field {entry_weight_limit}kg}"
    )
  } else {
    cli::cli_alert_success(
      "All responders' entry weights are within limit {.field {entry_weight_limit}kg}"
    )
  }

  # Exit weight check results
  if (num_underweight > 0) {
    cli::cli_alert_danger(
      "Found {.field {cli::col_red(num_underweight)}} responder{?s} below exit weight limit of {.field {exit_weight_limit}kg}"
    )
  } else {
    cli::cli_alert_success(
      "All responders' exit weights are exceeding limit {.field {exit_weight_limit}kg}"
    )
  }

  # Summary of deleted responders
  deleted_responders <- unique(c(
    overweight_responders$responder,
    underweight_responders$responder
  ))

  # Final statistics (在检查结果后面)
  total_responders <- length(unique(data$responder))
  remaining_responders <- total_responders - length(deleted_responders)

  #cli::cli_rule("Summary")
  cli::cli_bullets(c(
    "*" = "Initial responders: {.field {total_responders}}",
    "*" = "Removed responders: {.field {cli::col_red(length(deleted_responders))}}",
    "*" = "Remaining responders: {.field {remaining_responders}}"
  ))

  # Affected responders details
  if (length(deleted_responders) > 0) {
    cli::cli_rule("Deleted Responders")
    cli::cli_alert_warning("Total deleted responder{?s}: {.field {cli::col_red(length(deleted_responders))}}")
    cli::cli_code(sprintf(
      'c("%s")',
      paste(deleted_responders, collapse = '","')
    ))
  }

  # Return filtered data
  return(data_filtered[!responder %in% underweight_responders$responder, !c("temp")])
}
